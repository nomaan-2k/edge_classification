{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Edge Classifier Graph Neural Network\n",
    "\n",
    "The task is to train an edge classifier graph neural network to classify edges of graphs as true or false. \n",
    "Each graph is represented by a PyTorch Geometric (PyG) Data object with the following format:\n",
    "  \n",
    "> Data(x=[290, 6], edge_index=[2, 2690], edge_attr=[2690, 4], y=[2690])\n",
    "\n",
    "- Each node has 6 attributes\n",
    "- Each edge has 4 attributes\n",
    "- edge_index stores the indices of the nodes that are connected by each edge.\n",
    "- Array y stores a binary label (True or False) for each edge describing its class\n",
    "\n",
    "\n",
    "\n",
    "**!! UPDATE PATH TO DATASET BEFORE RUNNING JUPYTER NOTEBOOK !!** \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pathlib import Path    #for dataset path\n",
    "from torch.utils.data import Dataset    \n",
    "import torch                #pytorch\n",
    "from torch.utils.data import random_split    # to split data \n",
    "from torch_geometric.loader import DataLoader    # dataloader\n",
    "from torch.nn import Linear             # for linear classification \n",
    "from torch_geometric.nn import GCNConv    # for Graph Convolutional Networks\n",
    "from torch_geometric.logging import log    # to log data\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# custom dataset class provided in task\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, path: Path):\n",
    "        super().__init__()\n",
    "        self.graphs = list(path.glob(\"*.pt\"))    \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.load(self.graphs[idx])   \n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.graphs)\n",
    "\n",
    "\n",
    "# load the dataset\n",
    "# !! UPDATE PATH BEFORE RUNNING SCRIPT !!\n",
    "\n",
    "dataset = MyDataset(Path(\"/path/to/my/extracted/data\"))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### Split into Training and Testing parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Split the dataset into a 70/30 ratio for training and testing respectively\n",
    "train_size = int(0.7 * len(dataset))  \n",
    "test_size = len(dataset) - train_size \n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "# load mini batched of data\n",
    "train_loader = DataLoader(train_dataset, batch_size=32,shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### Define the GNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define edge classifier model\n",
    "\n",
    "class Edge_classifier(torch.nn.Module):\n",
    "\n",
    "\n",
    "    def __init__(self, input_layer, hidden_layer1, hidden_layer2): \n",
    "        super(Edge_classifier, self).__init__()\n",
    "\n",
    "        # two graph convolutional layers\n",
    "        self.conv1 = GCNConv(input_layer, hidden_layer1)\n",
    "        self.conv2 = GCNConv(hidden_layer1, hidden_layer2)\n",
    "\n",
    "        # linear layer to classify the edges\n",
    "        self.lin = Linear(2 * hidden_layer2 + 4, 2)         \n",
    "        \n",
    "        # (2*hidden_layer2 + 4) due to concatenation of x_src, edge_attr & x_dst into edge_feat\n",
    "\n",
    "\n",
    "    # forward method to perform forward pass\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "\n",
    "        R = torch.nn.ReLU()    # activation function\n",
    "\n",
    "        # convolution layers with ReLU activation\n",
    "        x = R(self.conv1(x, edge_index))\n",
    "        x = R(self.conv2(x, edge_index))\n",
    "\n",
    "        # Concatenate the source node features, destination node features, and edge attributes\n",
    "        x_src, x_dst = x[edge_index[0]], x[edge_index[1]]\n",
    "        edge_feat = torch.cat([x_src, edge_attr, x_dst], dim=-1)\n",
    "\n",
    "        # linear classifier\n",
    "        # this classifies edges as true or false using edge_feat as input\n",
    "        edge_pred = self.lin(edge_feat)\n",
    "        \n",
    "        # we can use softmax method from torch.nn.functional to get probabilities\n",
    "        # but as we are using cross entropy loss function, it can handle the predicted output directly\n",
    "\n",
    "        # return predicted edge labels\n",
    "        return edge_pred"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### Instantiate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Instantiate the Edge Classifier model\n",
    "model = Edge_classifier(6,8,4)\n",
    "\n",
    "# cross entropy loss\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# adam optimizer with learning rate = 0.01\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### Training and Testing Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# define a training method\n",
    "\n",
    "def train():\n",
    "\n",
    "    # training mode\n",
    "    model.train()\n",
    "\n",
    "    total_loss = 0\n",
    "\n",
    "    # iterate over the training data loader\n",
    "    for data in train_loader:\n",
    "\n",
    "        # set gradients to zero\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward pass through the model\n",
    "        out = model(data.x, data.edge_index, data.edge_attr)\n",
    "\n",
    "        # calculate loss\n",
    "        loss = criterion(out, data.y.long())\n",
    "\n",
    "        # backward pass and update weights and biases\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += float(loss) * data.num_graphs\n",
    "        \n",
    "    # return average loss\n",
    "    return total_loss / len(train_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# define a testing method\n",
    "\n",
    "def test(loader):\n",
    "\n",
    "    # evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    total_correct = 0      # correct predictions\n",
    "    num_pred = 0           # total predictions made\n",
    "\n",
    "    # iterate over the data loader\n",
    "    for data in loader:\n",
    "\n",
    "        # forward pass\n",
    "        pred = model(data.x, data.edge_index, data.edge_attr).argmax(dim=-1)\n",
    "\n",
    "        # no of correct predictions\n",
    "        total_correct += (pred == data.y.long()).sum()\n",
    "\n",
    "        # update total number of predictions\n",
    "        num_pred += len(pred)\n",
    "        \n",
    "    # return the accuracy\n",
    "    return int(total_correct) / int(num_pred)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### Train the Model to make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# train the model for 200 epochs\n",
    "for epoch in range(200):\n",
    "\n",
    "    # trains the model and returns average loss for each epoch\n",
    "    loss = train()\n",
    "\n",
    "    # get training and test accuracy at each step\n",
    "    train_acc = test(train_loader)\n",
    "    test_acc = test(test_loader)\n",
    "\n",
    "    # log the data\n",
    "    log(Epoch=epoch, Loss=loss, Train_Accuracy=train_acc, Test_Accuracy=test_acc)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnn_tracking",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d2c9b495bcea6f8ea6aa57ab2af1bfa27705fece773aa418d7156a738eb7564e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
